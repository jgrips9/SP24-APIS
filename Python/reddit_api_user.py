# -*- coding: utf-8 -*-
"""Reddit API User.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aezucTWwQ4Ai5SuR144bt2zPwcsZU19G

#Setup
Reddit requires keys to submit API requests. Keys are free to get. Instructions included below on how you can access reddit API.

Create a reddit user and developer account using the link below. When creating developer account select 'script' option for personal use:

[reddit.com/prefs/apps](https://reddit.com/prefs/apps)


Creating developer account will provide you with access token and secret token. Copy these and save somewhere safe.

Once you have reddit user and developer account, request access to use by filling out form. Upon completing form you will have access. My access was immediate, but times can differ.

[https://docs.google.com/forms/d/e/1FAIpQLSezNdDNK1-P8mspSbmtC2r86Ee9ZRbC66u929cG2GX0T9UMyw/viewform](https://docs.google.com/forms/d/e/1FAIpQLSezNdDNK1-P8mspSbmtC2r86Ee9ZRbC66u929cG2GX0T9UMyw/viewform)

List of API fields available to pull from.
[Reddit fields](https://www.reddit.com/dev/api/#fullnames)

What the API data looks like. The data you are pulling from.
[Reddit API data](https://www.reddit.com/r/python/top.json?limit=100&t=year)

Below I will provide sample code but not my credentials. You may input yours in when prompted.

#Sample Code
"""

#Import libraries
import requests

#input credentials for access and secret.
access = ''
secret = ''

# note that CLIENT_ID refers to 'personal use script' and SECRET_TOKEN to 'token'
auth = requests.auth.HTTPBasicAuth('', '')

# here we pass our login method (password), username, and password
data = {'grant_type': 'password',
        'username': '',
        'password': ''}

# setup our header info, which gives reddit a brief description of our app
headers = {'User-Agent': 'MyBot/0.0.1'}

# send our request for an OAuth token
res = requests.post('https://www.reddit.com/api/v1/access_token',
                    auth=auth, data=data, headers=headers)

# convert response to JSON and pull access_token value
TOKEN = res.json()['access_token']

# add authorization to our headers dictionary
headers = {**headers, **{'Authorization': f"bearer {TOKEN}"}}

# while the token is valid (~2 hours) we just add headers=headers to our requests
requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)

"""The program accepts my tokens, login credentials and stores within the bearer token. Bearer token is then stored into headers and added to URL when submitting requests.

Result of 'Response 200' is success.
"""

#Pull a request. Trending posts related to python.
res = requests.get("https://oauth.reddit.com/r/python/hot",
                   headers=headers)

print(res.json())  # let's see what we get. Similar to the webpage URL from the beginning.

"""#Structure
Data attribute contains all information, children is layer below that. Containing each individual entry for number of requests pulled, 15 min 100 max. Data again is another layer deep from children containing desired metadata. First and second data are different.
"""

#The above object has attributes. Like title of post.
#Attributes/Fields that we can pull from are included in link below from reddit documentation
#https://www.reddit.com/dev/api/


for post in res.json()['data']['children']:
    print(post['data']['title'])

"""#Pulling More Data
In the following request we will pull much more data. title, text, ups, downs count, score, etc.

This search will be on the trending searches based on a keyword. Searching the trending searches for 'python'. look at URL. 'hot' refers to trending.
"""

#Now place into a dataframe.
#Pull title, date-time, content, reactions
# make a request for the trending posts in /r/Python. hot keyword means treanding.
import pandas as pd
res = requests.get("https://oauth.reddit.com/r/python/hot",
                   headers=headers)

df = pd.DataFrame()  # initialize dataframe

# loop through each post retrieved from GET request
for post in res.json()['data']['children']:
    # append relevant data to dataframe
    df = df.append({
        'subreddit': post['data']['subreddit'],
        'title': post['data']['title'],
        'selftext': post['data']['selftext'],
        'upvote_ratio': post['data']['upvote_ratio'],
        'ups': post['data']['ups'],
        'downs': post['data']['downs'],
        'score': post['data']['score'],
        'name': post['data']['name']
    }, ignore_index=True)

display(df)

"""Next request will still include the keyword Python. But this time will search for the most recent results rather than the hottest."""

# make a request for the most recent posts in /r/Python. instead of hot this time new
res = requests.get("https://oauth.reddit.com/r/python/new",
                   headers=headers)

df = pd.DataFrame()  # initialize dataframe
#URL below section 'Pulling all the most recent posts in a subreddit and creating a local database' gray box shows fields allowed to pull.
#https://brentgaisford.medium.com/how-to-use-python-and-the-reddit-api-to-build-a-local-database-of-reddit-posts-and-comments-ca9f3843bfc2

# loop through each post retrieved from GET request
for post in res.json()['data']['children']:
    # append relevant data to dataframe
    df = df.append({
        'subreddit': post['data']['subreddit'],
        'title': post['data']['title'],
        'selftext': post['data']['selftext'],
        'upvote_ratio': post['data']['upvote_ratio'],
        'ups': post['data']['ups'],
        'downs': post['data']['downs'],
        'score': post['data']['score'],
        'author': post['data']['author'],
        'comments_count': post['data']['num_comments']
    }, ignore_index=True)

display(df)

"""#Another Reddit API feature within Reddit. Praw
a python package to scrape Reddit Post data. This package provides the scraper with more power to filter requests
"""

!pip install praw
import praw

#Input credentials. client_id is access token. 'user_agent' is name of developer account.
reddit = praw.Reddit(client_id='K-GqWsrNzjiEs9EsuCzmkg',
                     client_secret='IKGSFyS7-H3yMcG6rNkyQAv2kfX1MQ', password='InTr8O_Smippl$',
                     user_agent='red_test1', username='jgrips9')

#Create empty lists. This is where data will be stored
author_list = []

"""Top reddit posts for searchword 'worldnews'"""

subreddit = reddit.subreddit('worldnews')
hot_post = subreddit.hot(limit = 10)
for sub in hot_post:
  author_list.append(sub.author)

print(author_list)

#Search posts by a specific author.
subreddit1 = reddit.subreddit('worldnews')
posts = subreddit.search(query="author:WorldNewsMods", sort="new", limit=10)
for sub in posts:
  print(sub.author)
  print(sub.title)

#Storing more information.
author_list = []
id_list = []
num_comments_list = []
score_list = []
title_list = []
upvote_ratio_list = []
topic = []

#Searching more than 1 topic.
subreddit_list=  ['worldnews',
                  'announcements',
                  'funny',
                  'gaming',
                  'science',
                  'movies'
                 ]

#Store into dataframe. populate lists
for subred in subreddit_list:

  subreddit = reddit.subreddit(subred)
  hot_post = subreddit.hot(limit = 10)
  for sub in hot_post:
    author_list.append(sub.author)
    id_list.append(sub.id)
    num_comments_list.append(sub.num_comments)
    score_list.append(sub.score)
    title_list.append(sub.title)
    upvote_ratio_list.append(sub.upvote_ratio)
    topic.append(subred)

#Store in dataframe. create dataframe from lists
df = pd.DataFrame({'ID':id_list,
                   'Author':author_list,
                   'Title':title_list,
                   'Count_of_Comments':num_comments_list,
                   'Upvote_Count':score_list,
                   'Upvote_Ratio':upvote_ratio_list,
                   'topic': topic
                  })
display(df)

"""Perform the same action with top posts, new posts."""

author_list = []
id_list = []
num_comments_list = []
score_list = []
title_list = []
upvote_ratio_list = []
topic = []

for subred in subreddit_list:

  subreddit = reddit.subreddit(subred)
  top_post = subreddit.top(limit = 10)
  for sub in top_post:
    author_list.append(sub.author)
    id_list.append(sub.id)
    num_comments_list.append(sub.num_comments)
    score_list.append(sub.score)
    title_list.append(sub.title)
    upvote_ratio_list.append(sub.upvote_ratio)
    topic.append(subred)

#Store in dataframe. create dataframe from lists
df = pd.DataFrame({'ID':id_list,
                   'Author':author_list,
                   'Title':title_list,
                   'Count_of_Comments':num_comments_list,
                   'Upvote_Count':score_list,
                   'Upvote_Ratio':upvote_ratio_list,
                   'topic': topic
                  })
display(df)

author_list = []
id_list = []
num_comments_list = []
score_list = []
title_list = []
upvote_ratio_list = []
topic = []

for subred in subreddit_list:

  subreddit = reddit.subreddit(subred)
  new_post = subreddit.new(limit = 10)
  for sub in new_post:
    author_list.append(sub.author)
    id_list.append(sub.id)
    num_comments_list.append(sub.num_comments)
    score_list.append(sub.score)
    title_list.append(sub.title)
    upvote_ratio_list.append(sub.upvote_ratio)
    topic.append(subred)

#Store in dataframe. create dataframe from lists
df = pd.DataFrame({'ID':id_list,
                   'Author':author_list,
                   'Title':title_list,
                   'Count_of_Comments':num_comments_list,
                   'Upvote_Count':score_list,
                   'Upvote_Ratio':upvote_ratio_list,
                   'topic': topic
                  })
display(df)

"""#Helpful Information
[Setup and sample Python code.](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c)

Praw tutorial and code
[Praw tutorial](https://medium.com/analytics-vidhya/praw-a-python-package-to-scrape-reddit-post-data-b759a339ed9a)
"""